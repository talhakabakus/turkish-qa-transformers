{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distilbert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-05T16:11:25.597016Z",
     "iopub.status.busy": "2025-02-05T16:11:25.596680Z",
     "iopub.status.idle": "2025-02-05T17:37:01.272411Z",
     "shell.execute_reply": "2025-02-05T17:37:01.271607Z",
     "shell.execute_reply.started": "2025-02-05T16:11:25.596986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyin\n",
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veri dosyalarını yükleyin\n",
    "train_file = \"/kaggle/input/enelpi-q-a/questions_and_answers.csv\"\n",
    "test_file = \"/kaggle/input/enelpi-q-a/test_questions_and_answers.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Küçük bir alt set oluşturun (ilk 200 örnek)\n",
    "small_train_data = train_data#.head(1000)\n",
    "small_test_data = test_data#.head(100)\n",
    "\n",
    "# Dataset sınıfını tanımlayın\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row[\"question\"]\n",
    "        context = row[\"context\"]\n",
    "        answer = row[\"answer\"]\n",
    "\n",
    "        # Tokenize işlemi\n",
    "        inputs = self.tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True  # offset_mapping'i ekliyoruz\n",
    "        )\n",
    "\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\").squeeze(0)\n",
    "        start_char_idx = context.find(answer)\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "\n",
    "        # Offset mapping ile token pozisyonlarını belirleme\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "\n",
    "        for idx, (start, end) in enumerate(offset_mapping):\n",
    "            if start <= start_char_idx < end:\n",
    "                start_token_idx = idx\n",
    "            if start < end_char_idx <= end:\n",
    "                end_token_idx = idx\n",
    "\n",
    "        if start_token_idx is None or end_token_idx is None:\n",
    "            start_token_idx = 0\n",
    "            end_token_idx = 0\n",
    "\n",
    "        inputs[\"start_positions\"] = torch.tensor(start_token_idx, dtype=torch.long)\n",
    "        inputs[\"end_positions\"] = torch.tensor(end_token_idx, dtype=torch.long)\n",
    "\n",
    "        return {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "# Model ve Tokenizer'ı yükleyin\n",
    "model_name = \"distilbert-base-cased\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Dataset ve DataLoader oluşturun\n",
    "train_dataset = QADataset(small_train_data, tokenizer)\n",
    "test_dataset = QADataset(small_test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Optimizasyon ve öğrenme planı\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# GPU kullanımı kontrolü\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        train_loss_values.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # Validation Loss hesaplama\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = {key: val.to(device) for key, val in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                val_loss += outputs.loss.item()\n",
    "        val_loss_values.append(val_loss / len(test_loader))\n",
    "\n",
    "    return train_loss_values, val_loss_values\n",
    "\n",
    "# Değerlendirme fonksiyonu\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# F1 ve EM metriklerini yükle\n",
    "metric_f1 = load(\"f1\")\n",
    "metric_em = load(\"exact_match\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_f1_score(str1, str2):\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "    \n",
    "    # Create Counter objects for both strings\n",
    "    counter1 = Counter(tokens1)\n",
    "    counter2 = Counter(tokens2)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    common_tokens = sum((counter1 & counter2).values())\n",
    "    precision = common_tokens / len(tokens2) if len(tokens2) > 0 else 0\n",
    "    recall = common_tokens / len(tokens1) if len(tokens1) > 0 else 0\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    \"\"\"\n",
    "    İki string arasındaki BLEU skorunu hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        reference_text (str): Referans metin (doğru çeviri).\n",
    "        candidate_text (str): Modelin ürettiği metin (hipotez).\n",
    "    \n",
    "    Returns:\n",
    "        float: Hesaplanan BLEU skoru (0 ile 1 arasında bir değer).\n",
    "    \"\"\"\n",
    "    # Metinleri kelime bazlı tokenize et\n",
    "    reference = [reference_text.split()]  # Referans listesi içinde bir liste olmalı\n",
    "    candidate = candidate_text.split()   # Modelin çıktısı tokenize edilmiş\n",
    "    \n",
    "    # BLEU skorunu hesapla\n",
    "    smooth_fn = SmoothingFunction().method1  # Küçük veri setleri için smoothing kullanılır\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "import traceback\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, tokenizer):\n",
    "    model.eval()\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    # Test setini değerlendir\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "            # En yüksek olasılıkla başlama ve bitiş token'larını tahmin et\n",
    "            start_pred = torch.argmax(start_logits, dim=-1)\n",
    "            end_pred = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(len(start_pred)):\n",
    "                # token id'leri ile pozisyonları al\n",
    "                start_position = start_pred[i].item()\n",
    "                end_position = end_pred[i].item()\n",
    "\n",
    "                # Token'ları decode et\n",
    "                input_ids = batch['input_ids'][i].cpu().numpy()\n",
    "                pred_text = tokenizer.decode(input_ids[start_position:end_position + 1], skip_special_tokens=True)\n",
    "                \n",
    "                # Referans metni\n",
    "                ref_start = batch[\"start_positions\"][i].item()\n",
    "                ref_end = batch[\"end_positions\"][i].item()\n",
    "                ref_text = tokenizer.decode(input_ids[ref_start:ref_end + 1], skip_special_tokens=True)\n",
    "\n",
    "                # Eğer boş bir metin varsa, bunları atlayalım\n",
    "                if not pred_text or not ref_text:\n",
    "                    continue\n",
    "\n",
    "                # F1 ve EM hesaplama\n",
    "                try:\n",
    "                    #f1 = metric_f1.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    f1 = calculate_f1_score(pred_text, ref_text)\n",
    "                    em = metric_em.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    bleu_score_tmp = calculate_bleu(pred_text, ref_text)\n",
    "\n",
    "                    f1_scores.append(f1)\n",
    "                    em_scores.append(em[\"exact_match\"])\n",
    "                    bleu_scores.append(bleu_score_tmp)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError for prediction: {pred_text} and reference: {ref_text} -> {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "                # İstenirse hata durumunu yazdır\n",
    "                #if pred_text != ref_text:\n",
    "                    #print(f\"Predicted Text: {pred_text}\")\n",
    "                    #print(f\"Reference Text: {ref_text}\")\n",
    "                    #print(f\"Error with prediction: {pred_text} and reference: {ref_text}\")\n",
    "\n",
    "    # Ortalama F1 ve EM skorlarını hesapla\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "    avg_em = sum(em_scores) / len(em_scores) if em_scores else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "\n",
    "    return avg_f1, avg_em, avg_bleu\n",
    "\n",
    "# Eğitim süresi ve validation süresi hesaplama\n",
    "def main(is_train=True):\n",
    "    train_loss_values, val_loss_values = [], []\n",
    "    f1_score, em_score = 0, 0\n",
    "\n",
    "    if is_train:\n",
    "        train_start = time.time()\n",
    "        train_loss_values, val_loss_values = train(model, train_loader, optimizer, lr_scheduler, device)\n",
    "        train_end = time.time()\n",
    "        print(f\"Training Duration: {train_end - train_start} seconds.\")\n",
    "\n",
    "        # Eğitim ve validation loss grafiğini çizme\n",
    "        plt.plot(range(1, num_epochs + 1), train_loss_values, label='Train Loss')\n",
    "        plt.plot(range(1, num_epochs + 1), val_loss_values, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'loss_plot_{model_name.replace(\"/\", \"_\")}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Modeli kaydetme\n",
    "        torch.save(model.state_dict(), f\"model_{model_name.replace('/', '_')}.pth\")\n",
    "        print(f\"Model kaydedildi: model_{model_name.replace('/', '_')}.pth\")\n",
    "    else:\n",
    "        # Eğitim olmadan kaydedilen modeli yükleyin\n",
    "        model.load_state_dict(torch.load(f\"model_{model_name.replace('/', '_')}.pth\"))\n",
    "        model.to(device)\n",
    "        print(f\"Model yüklendi: model_{model_name.replace('/', '_')}.pth\")\n",
    "\n",
    "    # Test adımını çalıştırma\n",
    "    test_start = time.time()\n",
    "    f1_score, em_score, blue_sonuc = evaluate_model(model, test_loader, device, tokenizer)\n",
    "    test_end = time.time()\n",
    "    print(f\"Test Duration: {test_end - test_start} seconds.\")\n",
    "\n",
    "    # Sonuçları yazdırın\n",
    "    print(f\"Test F1 Skoru: {f1_score:.4f}\")\n",
    "    print(f\"Test Exact Match (EM) Skoru: {em_score:.4f}\")\n",
    "    print(f\"Test BLEU Skoru: {blue_sonuc:.4f}\")\n",
    "\n",
    "# Eğitim veya test işlemi başlatma\n",
    "is_train = True  # Eğitim yap, False olursa eğitilmiş modeli kullan\n",
    "main(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbmdz/bert-base-turkish-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T12:18:18.625189Z",
     "iopub.status.busy": "2025-02-01T12:18:18.624876Z",
     "iopub.status.idle": "2025-02-01T13:51:56.227213Z",
     "shell.execute_reply": "2025-02-01T13:51:56.226259Z",
     "shell.execute_reply.started": "2025-02-01T12:18:18.625166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyin\n",
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veri dosyalarını yükleyin\n",
    "train_file = \"/kaggle/input/enelpi-q-a/questions_and_answers.csv\"\n",
    "test_file = \"/kaggle/input/enelpi-q-a/test_questions_and_answers.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Küçük bir alt set oluşturun (ilk 200 örnek)\n",
    "small_train_data = train_data#.head(1000)\n",
    "small_test_data = test_data#.head(100)\n",
    "\n",
    "# Dataset sınıfını tanımlayın\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row[\"question\"]\n",
    "        context = row[\"context\"]\n",
    "        answer = row[\"answer\"]\n",
    "\n",
    "        # Tokenize işlemi\n",
    "        inputs = self.tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True  # offset_mapping'i ekliyoruz\n",
    "        )\n",
    "\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\").squeeze(0)\n",
    "        start_char_idx = context.find(answer)\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "\n",
    "        # Offset mapping ile token pozisyonlarını belirleme\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "\n",
    "        for idx, (start, end) in enumerate(offset_mapping):\n",
    "            if start <= start_char_idx < end:\n",
    "                start_token_idx = idx\n",
    "            if start < end_char_idx <= end:\n",
    "                end_token_idx = idx\n",
    "\n",
    "        if start_token_idx is None or end_token_idx is None:\n",
    "            start_token_idx = 0\n",
    "            end_token_idx = 0\n",
    "\n",
    "        inputs[\"start_positions\"] = torch.tensor(start_token_idx, dtype=torch.long)\n",
    "        inputs[\"end_positions\"] = torch.tensor(end_token_idx, dtype=torch.long)\n",
    "\n",
    "        return {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "# Model ve Tokenizer'ı yükleyin\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Dataset ve DataLoader oluşturun\n",
    "train_dataset = QADataset(small_train_data, tokenizer)\n",
    "test_dataset = QADataset(small_test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Optimizasyon ve öğrenme planı\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# GPU kullanımı kontrolü\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        train_loss_values.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # Validation Loss hesaplama\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = {key: val.to(device) for key, val in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                val_loss += outputs.loss.item()\n",
    "        val_loss_values.append(val_loss / len(test_loader))\n",
    "\n",
    "    return train_loss_values, val_loss_values\n",
    "\n",
    "# Değerlendirme fonksiyonu\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# F1 ve EM metriklerini yükle\n",
    "metric_f1 = load(\"f1\")\n",
    "metric_em = load(\"exact_match\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_f1_score(str1, str2):\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "    \n",
    "    # Create Counter objects for both strings\n",
    "    counter1 = Counter(tokens1)\n",
    "    counter2 = Counter(tokens2)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    common_tokens = sum((counter1 & counter2).values())\n",
    "    precision = common_tokens / len(tokens2) if len(tokens2) > 0 else 0\n",
    "    recall = common_tokens / len(tokens1) if len(tokens1) > 0 else 0\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    \"\"\"\n",
    "    İki string arasındaki BLEU skorunu hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        reference_text (str): Referans metin (doğru çeviri).\n",
    "        candidate_text (str): Modelin ürettiği metin (hipotez).\n",
    "    \n",
    "    Returns:\n",
    "        float: Hesaplanan BLEU skoru (0 ile 1 arasında bir değer).\n",
    "    \"\"\"\n",
    "    # Metinleri kelime bazlı tokenize et\n",
    "    reference = [reference_text.split()]  # Referans listesi içinde bir liste olmalı\n",
    "    candidate = candidate_text.split()   # Modelin çıktısı tokenize edilmiş\n",
    "    \n",
    "    # BLEU skorunu hesapla\n",
    "    smooth_fn = SmoothingFunction().method1  # Küçük veri setleri için smoothing kullanılır\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "import traceback\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, tokenizer):\n",
    "    model.eval()\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    # Test setini değerlendir\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "            # En yüksek olasılıkla başlama ve bitiş token'larını tahmin et\n",
    "            start_pred = torch.argmax(start_logits, dim=-1)\n",
    "            end_pred = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(len(start_pred)):\n",
    "                # token id'leri ile pozisyonları al\n",
    "                start_position = start_pred[i].item()\n",
    "                end_position = end_pred[i].item()\n",
    "\n",
    "                # Token'ları decode et\n",
    "                input_ids = batch['input_ids'][i].cpu().numpy()\n",
    "                pred_text = tokenizer.decode(input_ids[start_position:end_position + 1], skip_special_tokens=True)\n",
    "                \n",
    "                # Referans metni\n",
    "                ref_start = batch[\"start_positions\"][i].item()\n",
    "                ref_end = batch[\"end_positions\"][i].item()\n",
    "                ref_text = tokenizer.decode(input_ids[ref_start:ref_end + 1], skip_special_tokens=True)\n",
    "\n",
    "                # Eğer boş bir metin varsa, bunları atlayalım\n",
    "                if not pred_text or not ref_text:\n",
    "                    continue\n",
    "\n",
    "                # F1 ve EM hesaplama\n",
    "                try:\n",
    "                    #f1 = metric_f1.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    f1 = calculate_f1_score(pred_text, ref_text)\n",
    "                    em = metric_em.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    bleu_score_tmp = calculate_bleu(pred_text, ref_text)\n",
    "\n",
    "                    f1_scores.append(f1)\n",
    "                    em_scores.append(em[\"exact_match\"])\n",
    "                    bleu_scores.append(bleu_score_tmp)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError for prediction: {pred_text} and reference: {ref_text} -> {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "                # İstenirse hata durumunu yazdır\n",
    "                #if pred_text != ref_text:\n",
    "                    #print(f\"Predicted Text: {pred_text}\")\n",
    "                    #print(f\"Reference Text: {ref_text}\")\n",
    "                    #print(f\"Error with prediction: {pred_text} and reference: {ref_text}\")\n",
    "\n",
    "    # Ortalama F1 ve EM skorlarını hesapla\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "    avg_em = sum(em_scores) / len(em_scores) if em_scores else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "\n",
    "    return avg_f1, avg_em, avg_bleu\n",
    "\n",
    "# Eğitim süresi ve validation süresi hesaplama\n",
    "def main(is_train=True):\n",
    "    train_loss_values, val_loss_values = [], []\n",
    "    f1_score, em_score = 0, 0\n",
    "\n",
    "    if is_train:\n",
    "        train_start = time.time()\n",
    "        train_loss_values, val_loss_values = train(model, train_loader, optimizer, lr_scheduler, device)\n",
    "        train_end = time.time()\n",
    "        print(f\"Training Duration: {train_end - train_start} seconds.\")\n",
    "\n",
    "        # Eğitim ve validation loss grafiğini çizme\n",
    "        plt.plot(range(1, num_epochs + 1), train_loss_values, label='Train Loss')\n",
    "        plt.plot(range(1, num_epochs + 1), val_loss_values, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'loss_plot_{model_name.replace(\"/\", \"_\")}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Modeli kaydetme\n",
    "        torch.save(model.state_dict(), f\"model_{model_name.replace('/', '_')}.pth\")\n",
    "        print(f\"Model kaydedildi: model_{model_name.replace('/', '_')}.pth\")\n",
    "    else:\n",
    "        # Eğitim olmadan kaydedilen modeli yükleyin\n",
    "        model.load_state_dict(torch.load(f\"model_{model_name.replace('/', '_')}.pth\"))\n",
    "        model.to(device)\n",
    "        print(f\"Model yüklendi: model_{model_name.replace('/', '_')}.pth\")\n",
    "\n",
    "    # Test adımını çalıştırma\n",
    "    test_start = time.time()\n",
    "    f1_score, em_score, blue_sonuc = evaluate_model(model, test_loader, device, tokenizer)\n",
    "    test_end = time.time()\n",
    "    print(f\"Test Duration: {test_end - test_start} seconds.\")\n",
    "\n",
    "    # Sonuçları yazdırın\n",
    "    print(f\"Test F1 Skoru: {f1_score:.4f}\")\n",
    "    print(f\"Test Exact Match (EM) Skoru: {em_score:.4f}\")\n",
    "    print(f\"Test BLEU Skoru: {blue_sonuc:.4f}\")\n",
    "\n",
    "# Eğitim veya test işlemi başlatma\n",
    "is_train = True  # Eğitim yap, False olursa eğitilmiş modeli kullan\n",
    "main(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference BERTurk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-12T15:36:25.478Z",
     "iopub.execute_input": "2025-02-12T15:35:39.736640Z",
     "iopub.status.busy": "2025-02-12T15:35:39.736226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "\n",
    "# Model ve tokenizer'ı yükleme\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "model_path = f\"model_{model_name.replace('/', '_')}.pth\"\n",
    "\n",
    "# Tokenizer ve model yükleniyor\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Cihaz seçimi\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Kullanıcıdan soru ve bağlam alıp cevap üreten fonksiyon\n",
    "def answer_question(question, context):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        question,\n",
    "        context,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Modeli cihaza taşıma\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Model tahmini\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # En yüksek olasılıkla başlama ve bitiş pozisyonlarını belirleme\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits)\n",
    "\n",
    "    # Tahmin edilen cevabı çözümleme\n",
    "    answer_ids = inputs[\"input_ids\"][0][start_index: end_index + 1]\n",
    "    answer = tokenizer.decode(answer_ids, skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Kullanıcıdan sürekli giriş alıp cevap döndürme\n",
    "while True:\n",
    "    context = input(\"Lütfen bağlamı girin (çıkmak için 'q' yazın): \")\n",
    "    if context.lower() == 'q':\n",
    "        print(\"Çıkılıyor...\")\n",
    "        break\n",
    "    \n",
    "    question = input(\"Lütfen soruyu girin: \")\n",
    "    if question.lower() == 'q':\n",
    "        print(\"Çıkılıyor...\")\n",
    "        break\n",
    "\n",
    "    answer = answer_question(question, context)\n",
    "    print(f\"Cevap: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T23:34:12.232059Z",
     "iopub.status.busy": "2025-01-31T23:34:12.231677Z",
     "iopub.status.idle": "2025-02-01T01:27:07.657711Z",
     "shell.execute_reply": "2025-02-01T01:27:07.656804Z",
     "shell.execute_reply.started": "2025-01-31T23:34:12.232029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyin\n",
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veri dosyalarını yükleyin\n",
    "train_file = \"/kaggle/input/enelpi-q-a/questions_and_answers.csv\"\n",
    "test_file = \"/kaggle/input/enelpi-q-a/test_questions_and_answers.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Küçük bir alt set oluşturun (ilk 200 örnek)\n",
    "small_train_data = train_data#.head(200)\n",
    "small_test_data = test_data#.head(10)\n",
    "\n",
    "# Dataset sınıfını tanımlayın\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row[\"question\"]\n",
    "        context = row[\"context\"]\n",
    "        answer = row[\"answer\"]\n",
    "\n",
    "        # Tokenize işlemi\n",
    "        inputs = self.tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True  # offset_mapping'i ekliyoruz\n",
    "        )\n",
    "\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\").squeeze(0)\n",
    "        start_char_idx = context.find(answer)\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "\n",
    "        # Offset mapping ile token pozisyonlarını belirleme\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "\n",
    "        for idx, (start, end) in enumerate(offset_mapping):\n",
    "            if start <= start_char_idx < end:\n",
    "                start_token_idx = idx\n",
    "            if start < end_char_idx <= end:\n",
    "                end_token_idx = idx\n",
    "\n",
    "        if start_token_idx is None or end_token_idx is None:\n",
    "            start_token_idx = 0\n",
    "            end_token_idx = 0\n",
    "\n",
    "        inputs[\"start_positions\"] = torch.tensor(start_token_idx, dtype=torch.long)\n",
    "        inputs[\"end_positions\"] = torch.tensor(end_token_idx, dtype=torch.long)\n",
    "\n",
    "        return {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "# Model ve Tokenizer'ı yükleyin\n",
    "model_name = \"FacebookAI/xlm-roberta-base\"\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import XLMRobertaForQuestionAnswering\n",
    "\n",
    "# XLM-Roberta modelini yükleyin\n",
    "model = XLMRobertaForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Dataset ve DataLoader oluşturun\n",
    "train_dataset = QADataset(small_train_data, tokenizer)\n",
    "test_dataset = QADataset(small_test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Optimizasyon ve öğrenme planı\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# GPU kullanımı kontrolü\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        train_loss_values.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # Validation Loss hesaplama\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = {key: val.to(device) for key, val in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                val_loss += outputs.loss.item()\n",
    "        val_loss_values.append(val_loss / len(test_loader))\n",
    "\n",
    "    return train_loss_values, val_loss_values\n",
    "\n",
    "# Değerlendirme fonksiyonu\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# F1 ve EM metriklerini yükle\n",
    "metric_f1 = load(\"f1\")\n",
    "metric_em = load(\"exact_match\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_f1_score(str1, str2):\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "    \n",
    "    # Create Counter objects for both strings\n",
    "    counter1 = Counter(tokens1)\n",
    "    counter2 = Counter(tokens2)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    common_tokens = sum((counter1 & counter2).values())\n",
    "    precision = common_tokens / len(tokens2) if len(tokens2) > 0 else 0\n",
    "    recall = common_tokens / len(tokens1) if len(tokens1) > 0 else 0\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    \"\"\"\n",
    "    İki string arasındaki BLEU skorunu hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        reference_text (str): Referans metin (doğru çeviri).\n",
    "        candidate_text (str): Modelin ürettiği metin (hipotez).\n",
    "    \n",
    "    Returns:\n",
    "        float: Hesaplanan BLEU skoru (0 ile 1 arasında bir değer).\n",
    "    \"\"\"\n",
    "    # Metinleri kelime bazlı tokenize et\n",
    "    reference = [reference_text.split()]  # Referans listesi içinde bir liste olmalı\n",
    "    candidate = candidate_text.split()   # Modelin çıktısı tokenize edilmiş\n",
    "    \n",
    "    # BLEU skorunu hesapla\n",
    "    smooth_fn = SmoothingFunction().method1  # Küçük veri setleri için smoothing kullanılır\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "import traceback\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, tokenizer):\n",
    "    model.eval()\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    # Test setini değerlendir\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "            # En yüksek olasılıkla başlama ve bitiş token'larını tahmin et\n",
    "            start_pred = torch.argmax(start_logits, dim=-1)\n",
    "            end_pred = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(len(start_pred)):\n",
    "                # token id'leri ile pozisyonları al\n",
    "                start_position = start_pred[i].item()\n",
    "                end_position = end_pred[i].item()\n",
    "\n",
    "                # Token'ları decode et\n",
    "                input_ids = batch['input_ids'][i].cpu().numpy()\n",
    "                pred_text = tokenizer.decode(input_ids[start_position:end_position + 1], skip_special_tokens=True)\n",
    "                \n",
    "                # Referans metni\n",
    "                ref_start = batch[\"start_positions\"][i].item()\n",
    "                ref_end = batch[\"end_positions\"][i].item()\n",
    "                ref_text = tokenizer.decode(input_ids[ref_start:ref_end + 1], skip_special_tokens=True)\n",
    "\n",
    "                # Eğer boş bir metin varsa, bunları atlayalım\n",
    "                if not pred_text or not ref_text:\n",
    "                    continue\n",
    "\n",
    "                # F1 ve EM hesaplama\n",
    "                try:\n",
    "                    #f1 = metric_f1.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    f1 = calculate_f1_score(pred_text, ref_text)\n",
    "                    em = metric_em.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    bleu_score_tmp = calculate_bleu(pred_text, ref_text)\n",
    "\n",
    "                    f1_scores.append(f1)\n",
    "                    em_scores.append(em[\"exact_match\"])\n",
    "                    bleu_scores.append(bleu_score_tmp)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError for prediction: {pred_text} and reference: {ref_text} -> {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "                # İstenirse hata durumunu yazdır\n",
    "                #if pred_text != ref_text:\n",
    "                    #print(f\"Predicted Text: {pred_text}\")\n",
    "                    #print(f\"Reference Text: {ref_text}\")\n",
    "                    #print(f\"Error with prediction: {pred_text} and reference: {ref_text}\")\n",
    "\n",
    "    # Ortalama F1 ve EM skorlarını hesapla\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "    avg_em = sum(em_scores) / len(em_scores) if em_scores else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "\n",
    "    return avg_f1, avg_em, avg_bleu\n",
    "\n",
    "# Eğitim süresi ve validation süresi hesaplama\n",
    "def main(is_train=True):\n",
    "    train_loss_values, val_loss_values = [], []\n",
    "    f1_score, em_score = 0, 0\n",
    "\n",
    "    if is_train:\n",
    "        train_start = time.time()\n",
    "        train_loss_values, val_loss_values = train(model, train_loader, optimizer, lr_scheduler, device)\n",
    "        train_end = time.time()\n",
    "        print(f\"Training duration: {train_end - train_start}\")\n",
    "\n",
    "        # Eğitim ve validation loss grafiğini çizme\n",
    "        plt.plot(range(1, num_epochs + 1), train_loss_values, label='Train Loss')\n",
    "        plt.plot(range(1, num_epochs + 1), val_loss_values, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'loss_plot_{model_name.replace(\"/\", \"_\")}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Modeli kaydetme\n",
    "        torch.save(model.state_dict(), f\"model_{model_name.replace('/', '_')}.pth\")\n",
    "        print(f\"Model kaydedildi: model_{model_name.replace('/', '_')}.pth\")\n",
    "    else:\n",
    "        # Eğitim olmadan kaydedilen modeli yükleyin\n",
    "        model.load_state_dict(torch.load(f\"model_{model_name.replace('/', '_')}.pth\"))\n",
    "        model.to(device)\n",
    "        print(f\"Model yüklendi: model_{model_name.replace('/', '_')}.pth\")\n",
    "\n",
    "    # Test adımını çalıştırma\n",
    "    test_start = time.time()\n",
    "    f1_score, em_score, blue_sonuc = evaluate_model(model, test_loader, device, tokenizer)\n",
    "    test_end = time.time()\n",
    "    print(f\"Test duration: {test_end - test_start}\")\n",
    "\n",
    "    # Sonuçları yazdırın\n",
    "    print(f\"Test F1 Skoru: {f1_score:.4f}\")\n",
    "    print(f\"Test Exact Match (EM) Skoru: {em_score:.4f}\")\n",
    "    print(f\"Test BLEU Skoru: {blue_sonuc:.4f}\")\n",
    "\n",
    "# Eğitim veya test işlemi başlatma\n",
    "is_train = True  # Eğitim yap, False olursa eğitilmiş modeli kullan\n",
    "main(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbmdz/electra-base-turkish-cased-discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyin\n",
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Veri dosyalarını yükleyin\n",
    "train_file = \"/kaggle/input/enelpi-q-a/questions_and_answers.csv\"\n",
    "test_file = \"/kaggle/input/enelpi-q-a/test_questions_and_answers.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Küçük bir alt set oluşturun (ilk 200 örnek)\n",
    "small_train_data = train_data#.head(1000)\n",
    "small_test_data = test_data#.head(100)\n",
    "\n",
    "# Dataset sınıfını tanımlayın\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row[\"question\"]\n",
    "        context = row[\"context\"]\n",
    "        answer = row[\"answer\"]\n",
    "\n",
    "        # Tokenize işlemi\n",
    "        inputs = self.tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True  # offset_mapping'i ekliyoruz\n",
    "        )\n",
    "\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\").squeeze(0)\n",
    "        start_char_idx = context.find(answer)\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "\n",
    "        # Offset mapping ile token pozisyonlarını belirleme\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "\n",
    "        for idx, (start, end) in enumerate(offset_mapping):\n",
    "            if start <= start_char_idx < end:\n",
    "                start_token_idx = idx\n",
    "            if start < end_char_idx <= end:\n",
    "                end_token_idx = idx\n",
    "\n",
    "        if start_token_idx is None or end_token_idx is None:\n",
    "            start_token_idx = 0\n",
    "            end_token_idx = 0\n",
    "\n",
    "        inputs[\"start_positions\"] = torch.tensor(start_token_idx, dtype=torch.long)\n",
    "        inputs[\"end_positions\"] = torch.tensor(end_token_idx, dtype=torch.long)\n",
    "\n",
    "        return {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "# Model ve Tokenizer'ı yükleyin\n",
    "model_name = \"dbmdz/electra-base-turkish-cased-discriminator\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Dataset ve DataLoader oluşturun\n",
    "train_dataset = QADataset(small_train_data, tokenizer)\n",
    "test_dataset = QADataset(small_test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Optimizasyon ve öğrenme planı\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# GPU kullanımı kontrolü\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    train_loss_values = []\n",
    "    val_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        train_loss_values.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # Validation Loss hesaplama\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = {key: val.to(device) for key, val in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                val_loss += outputs.loss.item()\n",
    "        val_loss_values.append(val_loss / len(test_loader))\n",
    "\n",
    "    return train_loss_values, val_loss_values\n",
    "\n",
    "# Değerlendirme fonksiyonu\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# F1 ve EM metriklerini yükle\n",
    "metric_f1 = load(\"f1\")\n",
    "metric_em = load(\"exact_match\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_f1_score(str1, str2):\n",
    "    # Tokenize the strings\n",
    "    tokens1 = str1.split()\n",
    "    tokens2 = str2.split()\n",
    "    \n",
    "    # Create Counter objects for both strings\n",
    "    counter1 = Counter(tokens1)\n",
    "    counter2 = Counter(tokens2)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    common_tokens = sum((counter1 & counter2).values())\n",
    "    precision = common_tokens / len(tokens2) if len(tokens2) > 0 else 0\n",
    "    recall = common_tokens / len(tokens1) if len(tokens1) > 0 else 0\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    \"\"\"\n",
    "    İki string arasındaki BLEU skorunu hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        reference_text (str): Referans metin (doğru çeviri).\n",
    "        candidate_text (str): Modelin ürettiği metin (hipotez).\n",
    "    \n",
    "    Returns:\n",
    "        float: Hesaplanan BLEU skoru (0 ile 1 arasında bir değer).\n",
    "    \"\"\"\n",
    "    # Metinleri kelime bazlı tokenize et\n",
    "    reference = [reference_text.split()]  # Referans listesi içinde bir liste olmalı\n",
    "    candidate = candidate_text.split()   # Modelin çıktısı tokenize edilmiş\n",
    "    \n",
    "    # BLEU skorunu hesapla\n",
    "    smooth_fn = SmoothingFunction().method1  # Küçük veri setleri için smoothing kullanılır\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "import traceback\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, tokenizer):\n",
    "    model.eval()\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    # Test setini değerlendir\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "            # En yüksek olasılıkla başlama ve bitiş token'larını tahmin et\n",
    "            start_pred = torch.argmax(start_logits, dim=-1)\n",
    "            end_pred = torch.argmax(end_logits, dim=-1)\n",
    "\n",
    "            for i in range(len(start_pred)):\n",
    "                # token id'leri ile pozisyonları al\n",
    "                start_position = start_pred[i].item()\n",
    "                end_position = end_pred[i].item()\n",
    "\n",
    "                # Token'ları decode et\n",
    "                input_ids = batch['input_ids'][i].cpu().numpy()\n",
    "                pred_text = tokenizer.decode(input_ids[start_position:end_position + 1], skip_special_tokens=True)\n",
    "                \n",
    "                # Referans metni\n",
    "                ref_start = batch[\"start_positions\"][i].item()\n",
    "                ref_end = batch[\"end_positions\"][i].item()\n",
    "                ref_text = tokenizer.decode(input_ids[ref_start:ref_end + 1], skip_special_tokens=True)\n",
    "\n",
    "                # Eğer boş bir metin varsa, bunları atlayalım\n",
    "                if not pred_text or not ref_text:\n",
    "                    continue\n",
    "\n",
    "                # F1 ve EM hesaplama\n",
    "                try:\n",
    "                    #f1 = metric_f1.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    f1 = calculate_f1_score(pred_text, ref_text)\n",
    "                    em = metric_em.compute(predictions=[pred_text], references=[ref_text])\n",
    "                    bleu_score_tmp = calculate_bleu(pred_text, ref_text)\n",
    "\n",
    "                    f1_scores.append(f1)\n",
    "                    em_scores.append(em[\"exact_match\"])\n",
    "                    bleu_scores.append(bleu_score_tmp)\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError for prediction: {pred_text} and reference: {ref_text} -> {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "                # İstenirse hata durumunu yazdır\n",
    "                #if pred_text != ref_text:\n",
    "                    #print(f\"Predicted Text: {pred_text}\")\n",
    "                    #print(f\"Reference Text: {ref_text}\")\n",
    "                    #print(f\"Error with prediction: {pred_text} and reference: {ref_text}\")\n",
    "\n",
    "    # Ortalama F1 ve EM skorlarını hesapla\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "    avg_em = sum(em_scores) / len(em_scores) if em_scores else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "\n",
    "    return avg_f1, avg_em, avg_bleu\n",
    "\n",
    "# Eğitim süresi ve validation süresi hesaplama\n",
    "def main(is_train=True):\n",
    "    train_loss_values, val_loss_values = [], []\n",
    "    f1_score, em_score = 0, 0\n",
    "\n",
    "    if is_train:\n",
    "        train_start = time.time()\n",
    "        train_loss_values, val_loss_values = train(model, train_loader, optimizer, lr_scheduler, device)\n",
    "        train_end = time.time()\n",
    "        print(f\"Training duration: {train_end - train_start}\")\n",
    "\n",
    "        # Eğitim ve validation loss grafiğini çizme\n",
    "        plt.plot(range(1, num_epochs + 1), train_loss_values, label='Train Loss')\n",
    "        plt.plot(range(1, num_epochs + 1), val_loss_values, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'loss_plot_{model_name.replace(\"/\", \"_\")}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Modeli kaydetme\n",
    "        torch.save(model.state_dict(), f\"model_{model_name.replace('/', '_')}.pth\")\n",
    "        print(f\"Model kaydedildi: model_{model_name.replace('/', '_')}.pth\")\n",
    "    else:\n",
    "        # Eğitim olmadan kaydedilen modeli yükleyin\n",
    "        model.load_state_dict(torch.load(f\"model_{model_name.replace('/', '_')}.pth\"))\n",
    "        model.to(device)\n",
    "        print(f\"Model yüklendi: model_{model_name.replace('/', '_')}.pth\")\n",
    "\n",
    "    # Test adımını çalıştırma\n",
    "    test_start = time.time()\n",
    "    f1_score, em_score, blue_sonuc = evaluate_model(model, test_loader, device, tokenizer)\n",
    "    test_end = time.time()\n",
    "    print(f\"Training duration: {test_end - test_start}\")\n",
    "\n",
    "    # Sonuçları yazdırın\n",
    "    print(f\"Test F1 Skoru: {f1_score:.4f}\")\n",
    "    print(f\"Test Exact Match (EM) Skoru: {em_score:.4f}\")\n",
    "    print(f\"Test BLEU Skoru: {blue_sonuc:.4f}\")\n",
    "\n",
    "# Eğitim veya test işlemi başlatma\n",
    "is_train = True  # Eğitim yap, False olursa eğitilmiş modeli kullan\n",
    "main(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# google-t5/t5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T19:02:54.605591Z",
     "iopub.status.busy": "2025-02-05T19:02:54.605253Z",
     "iopub.status.idle": "2025-02-05T19:55:50.745208Z",
     "shell.execute_reply": "2025-02-05T19:55:50.744363Z",
     "shell.execute_reply.started": "2025-02-05T19:02:54.605565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Veri yükleme\n",
    "train_file = \"/kaggle/input/enelpi-q-a/questions_and_answers.csv\"\n",
    "test_file = \"/kaggle/input/enelpi-q-a/test_questions_and_answers.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# Model ismi\n",
    "model_name = \"google-t5/t5-small\"\n",
    "\n",
    "# Tokenizer ve model yükleme\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Verilerin birleştirilmesi\n",
    "train_df[\"input_text\"] = train_df[\"context\"] + \" \" + train_df[\"question\"]\n",
    "test_df[\"input_text\"] = test_df[\"context\"] + \" \" + test_df[\"question\"]\n",
    "\n",
    "# Küçük bir alt set seçimi\n",
    "train_df = train_df#.sample(100, random_state=42)  # Eğitim için 100 örnek\n",
    "test_df = test_df#.sample(20, random_state=42)    # Test için 20 örnek\n",
    "\n",
    "# Özel Dataset sınıfı\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        input_text = row[\"input_text\"]\n",
    "        target_text = row[\"answer\"]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        targets = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": targets[\"input_ids\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from collections import Counter\n",
    "\n",
    "# BLEU skoru hesaplama\n",
    "def calculate_bleu(reference_text, candidate_text):\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    bleu_score = sentence_bleu(reference_text, candidate_text, smoothing_function=smooth_fn)\n",
    "    return bleu_score\n",
    "\n",
    "# F1 skoru hesaplama\n",
    "def calculate_f1_score(preds, labels):\n",
    "    f1_scores = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        pred_tokens = Counter(pred)\n",
    "        label_tokens = Counter(label[0])  # Reference list içinde bir liste\n",
    "        common = pred_tokens & label_tokens\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            f1_scores.append(0)\n",
    "        else:\n",
    "            precision = num_same / len(pred)\n",
    "            recall = num_same / len(label[0])\n",
    "            f1_scores.append(2 * precision * recall / (precision + recall))\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Değerlendirme metrikleri\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # Tokenizer kullanarak metinlere dönüştürme\n",
    "    decoded_preds = [pred.split() for pred in tokenizer.batch_decode(pred_ids, skip_special_tokens=True)]\n",
    "    decoded_labels = [[label.split()] for label in tokenizer.batch_decode(labels_ids, skip_special_tokens=True)]\n",
    "\n",
    "    # F1 Skoru\n",
    "    f1 = calculate_f1_score(decoded_preds, decoded_labels)\n",
    "\n",
    "    # Exact Match (EM) Skoru\n",
    "    exact_match = np.mean([\n",
    "        int(\" \".join(pred) == \" \".join(label[0]))\n",
    "        for pred, label in zip(decoded_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # BLEU Skoru\n",
    "    bleu_score = np.mean([\n",
    "        calculate_bleu(label, pred)\n",
    "        for label, pred in zip(decoded_labels, decoded_preds)\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"exact_match\": exact_match,\n",
    "        \"bleu_score\": bleu_score\n",
    "    }\n",
    "\n",
    "# Dataset ve DataLoader oluşturma\n",
    "train_dataset = QADataset(train_df, tokenizer)\n",
    "test_dataset = QADataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Eğitim için ayarlar\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=\"none\",  # WANDB kapalı\n",
    ")\n",
    "\n",
    "# Trainer ayarları\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Eğitim veya değerlendirme için flag\n",
    "is_train = True  # Eğer False yaparsanız eğitim yapılmaz.\n",
    "\n",
    "if is_train:\n",
    "    # Eğitim\n",
    "    train_start = time.time()\n",
    "    trainer.train()\n",
    "    training_time = time.time() - train_start\n",
    "    print(f\"Eğitim süresi: {training_time:.2f} saniye\")\n",
    "\n",
    "    # Eğer tüm modeli kaydetmek isterseniz:\n",
    "    torch.save(model, f'model_{model_name.replace(\"/\", \"_\")}.pth')\n",
    "\n",
    "    # Eğitim ve doğrulama kayıpları grafiği\n",
    "    train_loss = trainer.state.log_history\n",
    "    train_losses = [x[\"loss\"] for x in train_loss if \"loss\" in x]\n",
    "    eval_losses = [x[\"eval_loss\"] for x in train_loss if \"eval_loss\" in x]\n",
    "\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(1, len(eval_losses) + 1), eval_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    #plt.title(\"Eğitim ve Doğrulama Kayıpları\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./loss_plot_{model_name.replace(\"/\", \"_\")}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Model eğitimi atlandı.\")\n",
    "\n",
    "# Test\n",
    "test_start = time.time()\n",
    "test_results = trainer.evaluate()\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "# Inference süresi\n",
    "start_time = time.time()\n",
    "sample = test_dataset[0]\n",
    "input_ids = sample[\"input_ids\"].unsqueeze(0).to(model.device)\n",
    "attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "\n",
    "generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Sonuçlar\n",
    "print(f\"Test süresi: {test_time:.2f} saniye\")\n",
    "print(f\"Inference süresi: {inference_time:.2f} saniye\")\n",
    "\n",
    "# Test sonuçları\n",
    "print(f\"Test F1 Skoru: {test_results['eval_f1']:.4f}\")\n",
    "print(f\"Test Exact Match (EM) Skoru: {test_results['eval_exact_match']:.4f}\")\n",
    "print(f\"Test BLEU Skoru: {test_results['eval_bleu_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6474206,
     "sourceId": 10460138,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
